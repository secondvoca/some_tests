{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secondvoca/anaconda3/envs/torch/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_cuda_device_or_cpu():\n",
    "  if torch.cuda.is_available():\n",
    "    cuda_count = torch.cuda.device_count()\n",
    "    \n",
    "    no = 0\n",
    "    mem_available = 0\n",
    "\n",
    "    for i in range(cuda_count):\n",
    "      tmp_available = torch.cuda.mem_get_info(i)[0]\n",
    "      if mem_available < tmp_available:\n",
    "        no = i\n",
    "        mem_available = tmp_available\n",
    "    return f'cuda:{no}'\n",
    "  return 'cpu'\n",
    "\n",
    "def get_model(dim_z: int, batch_size=128, less_than=10):\n",
    "\n",
    "  # Download training data from open datasets.\n",
    "  training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "  )\n",
    "\n",
    "  training_data.data = training_data.data[training_data.targets < less_than]\n",
    "  training_data.targets = training_data.targets[training_data.targets < less_than]\n",
    "\n",
    "  # Create data loaders.\n",
    "  dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  encoder = nn.Sequential(\n",
    "    nn.Linear(784, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, dim_z),\n",
    "  )\n",
    "\n",
    "  decoder = nn.Sequential(\n",
    "    nn.Linear(2, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 784),\n",
    "    nn.Sigmoid(),\n",
    "  )\n",
    "\n",
    "  model = nn.Sequential(OrderedDict([\n",
    "            ('encoder', encoder),\n",
    "            ('decoder', decoder),\n",
    "          ]))\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "  return model, dataloader, optimizer\n",
    "\n",
    "def train(model, dataloader, optimizer, run, epochs=5):\n",
    "  \n",
    "  device = get_cuda_device_or_cpu()\n",
    "  print(device)\n",
    "  \n",
    "  model.to(device)\n",
    "  model.train()\n",
    "\n",
    "  hist = torch.zeros(0)\n",
    "\n",
    "  for _ in tqdm(range(epochs)):\n",
    "    tmp = run(model, dataloader, optimizer, device)\n",
    "    hist = torch.cat([hist, tmp])\n",
    "  \n",
    "  return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/secondvoca/some_tests/sp1.ipynb Cell 2\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m hist\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m model, dataloader, optimizer \u001b[39m=\u001b[39m get_model(dim_z\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m hist \u001b[39m=\u001b[39m train(model, dataloader, optimizer, run_un, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(hist)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;32m/home/secondvoca/some_tests/sp1.ipynb Cell 2\u001b[0m in \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m device \u001b[39m=\u001b[39m get_cuda_device_or_cpu()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba101/home/secondvoca/some_tests/sp1.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m hist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "def run_un(model, dataloader, optimizer):\n",
    "\n",
    "  hist = torch.zeros(len(dataloader))\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for batch, (x, y) in enumerate(dataloader):\n",
    "    x = x.view([-1, 28*28]).to(device)\n",
    "    z = model.get_submodule('encoder')(x)\n",
    "    pred = model.get_submodule('decoder')(z)\n",
    "    loss = F.binary_cross_entropy(pred, x, reduction='sum')/len(x)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    hist[batch] = loss.item()\n",
    "\n",
    "  return hist\n",
    "  \n",
    "model, dataloader, optimizer = get_model(dim_z=2)\n",
    "hist = train(model, dataloader, optimizer, run_un, 5)\n",
    "plt.plot(hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, dataloader, optimizer = get_model(dim_z=2, batch_size=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in dataloader:\n",
    "  print()\n",
    "  plt.imshow(x.mean(dim=0)[0].view([28, 28]))\n",
    "  plt.axis('off')\n",
    "  break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
